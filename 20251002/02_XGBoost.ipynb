{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90741e45",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "- Boosting 중 대표적인 모델\n",
    "- Gradient Boosting 알고리즘을 고도화한 모델\n",
    "- 빠른속도, 높은 성능, 과적합 제어 기능을 제공하는 트리 기반 앙상블 모델\n",
    "- XGBoost는 sklearn에 존재x, 별도의 라이브러리 설치\n",
    "- 대규모 데이터에서 자주 사용되는 모델\n",
    "- 분류(XGBoostClassifier)와 회귀(XGBoostRegressor) 모두 가능\n",
    "\n",
    "- 매개변수\n",
    "    1. 학습 제어 관련\n",
    "        - n_estimators\n",
    "            - 기본값 : 100\n",
    "            - 트리가 생성이되는 개수 (모델의 개수)\n",
    "            - 클수록 성능이 올라가지만 계산이 많아지면서 시간은 오래걸린다.\n",
    "        - learning-rate\n",
    "            - 기본값 : 0.1\n",
    "            - 각 단계별 학습율 (기여도)\n",
    "            - 작을수록 데이터의 단순화, 클수록 데이터가 복잡\n",
    "        - early_stopping_rounds\n",
    "            - fit() 함수에서 'eval_set'에서 지정된 평가지표가 n라운드 연속 개선되지 않으면 학습 중단\n",
    "            - n_estimators의 값을 크게 잡고 이 값으로 최적의 라운드 검색\n",
    "        - objective\n",
    "            - 손실 함수 지정\n",
    "            - 분류\n",
    "                - \"binary:logistic\"\n",
    "                    - 이진분류용(0/1)\n",
    "                    - 출력 : 확률\n",
    "                    - predict_proba와 연결\n",
    "                - \"binary:logiraw\"\n",
    "                    - 이진분류\n",
    "                    - 출력 : 로짓(log-odds) 값 (확률 x)\n",
    "                    - 확률 후의 처리를 직접 사용\n",
    "                - \"multi:softmax\"\n",
    "                    - 다중 클래스 분류\n",
    "                    - 출력: 클래스의 인덱스(정수)\n",
    "                - \"multi:softprob\"\n",
    "                    - 다중 클래스 분류\n",
    "                    - 출력 : 각 클래스별 확률 벡터\n",
    "                    - 확률 기반 후처리 / 평가에 적합\n",
    "            - 회귀\n",
    "                - \"reg:squarederror\"\n",
    "                    - 평균 제곱 오차(MSE) 기반\n",
    "                    - 일반적인 연속형 데이터 예측 사용\n",
    "                - \"reg:abosoluteerror\"\n",
    "                    - 평균 절대 오차(MAE) 기반\n",
    "                    - 이상치 데이터에 대해서 유리\n",
    "                - \"reg:squaredlogerror\"\n",
    "                    - 로그 평균 제곱 오차(MSLE) 기반\n",
    "                    - 종속 데이터가 양수이고 값의 범위가 넓을 때 유리\n",
    "                - \"reg:pseudohubererror\"\n",
    "                    - pseudo-huber 손실 기반\n",
    "                    - MSE와 MAE의 절충 -> 이상치에 완화된 영향\n",
    "        - eval_metric\n",
    "            - 기본값 : None\n",
    "            - 검증시 사용할 평가 지표\n",
    "            - 조기 종료(earlt_stopping_rounds)와 함께 사용\n",
    "            - 분류 : \"logloss\", \"auc\", \"error\"\n",
    "            - 회귀 : \"RMSE\", \"MAE\" 등\n",
    "    \n",
    "    2. 트리 구조 제어\n",
    "        - max_depth\n",
    "            - 기본값 : 6\n",
    "            - 트리의 최대 깊이를 지정\n",
    "            - 값이 커질수록 복잡도 증가, 과적합 위험\n",
    "            - 일반적으로 깊이는 3~10 사용\n",
    "        - min_child_weight\n",
    "            - 기본값 : 1.0\n",
    "            - leaf node가 분할되기 위한 최소 가중치\n",
    "            - 값이 커질수록 보수적인 분할(과적합 위험이 내려간다.)\n",
    "            - 값이 작을수록 세밀한 분할\n",
    "        - gamma\n",
    "            - 기본값 : 0\n",
    "            - 리프 추가 분할에 필요한 최소 손실 감소값\n",
    "            - 값이 커지면 불필요한 분할 억제 (과적합 방지)\n",
    "        - max_leave\n",
    "            - 리프 노드의 개수를 제한\n",
    "            - 깊이 대신 리프의 개수로 복잡도를 제어\n",
    "    \n",
    "    3. 샘플링 / 다양성 제어\n",
    "        - subsample\n",
    "            - 기본값 : 1.0\n",
    "            - 각 트리의 학습에서 사용할 샘플의 비율\n",
    "            - 일반적으로 0.6~0.9 사용 ->  과적합 위험도를 줄이고 다양성 증가\n",
    "        - colsample_bytree\n",
    "            - 기본값 :1.0\n",
    "            - 각 트리의 학습에서 사용할 샘플의 피쳐의 비율\n",
    "            - 일반적으로 0.5~0.9 -> 일반화 \n",
    "        - colsample_bylevel / closample_bynode\n",
    "            - 레벨 / 노드 단위에서 추가 특징 샘플링\n",
    "            - 미세한 조정이 필요한 경우라면 사용\n",
    "    \n",
    "    4. 정규화 / 규제 (회귀)\n",
    "        - reg_lambda\n",
    "            - 기본값 : 1.0\n",
    "            - L2 정규화 (가중치 크기 억제)\n",
    "            - 값이 커지면 안정적인 모델, 과적합 방지\n",
    "        - reg_alpha\n",
    "            - 기본값 : 0.0\n",
    "            - L1 정규화 (가중치 희소화)\n",
    "            - 피쳐 선택 효과\n",
    "            - 고차원 데이터에 유용\n",
    "    \n",
    "    5. 데이터 불균형 처리 (분류)\n",
    "        - scale_pos_weight\n",
    "            - 기본값 : 1\n",
    "            - 양성 / 음성 클래스 불균형 보장\n",
    "            - neg / pos 비율로 설정 (음성 90%, 양성 10% -> 9)\n",
    "\n",
    "    6. 실행 최적화\n",
    "        - tree_method\n",
    "            - 기본값 : \"auto\"\n",
    "            - \"auto\" : 자동 선택\n",
    "            - \"hist\" : 대규모 데이터 빠른 학습\n",
    "            - \"gpu_hist\" : GPU 가속 -> 대규모/고차원 데이터에서 권장\n",
    "        - max_bin\n",
    "            - 기본값 : 256\n",
    "            - 히스토그램의 버킷의 수 지정\n",
    "            - 값이 커지면 정화도 올라가지만 메모리의 사용량과 시간은 증가\n",
    "    \n",
    "    - 하이퍼 파라미터 튜닝에 일반적인 순서\n",
    "        1. 1순위\n",
    "            - n_estimator(트리개수), learning_rate(기여도)\n",
    "            - max_depth(최대 깊이)\n",
    "            - min_child_weight(최소 가중치의 합)\n",
    "        2. 2순위 (과적합, 일반화)\n",
    "            - gamma(손실)\n",
    "            - subsample(학습에 사용될 데이터의 비율)\n",
    "            - colsample_bytree(학습에 사용될 피쳐의 비율)\n",
    "        3. 3순위 (세밀한 조정 / 특수 케이스)\n",
    "            - reg_lambda, reg_alpha(정규화)\n",
    "            - scale_pos_weight(데이터 불균형)\n",
    "            - tree_method, max_bin(속도, 메모리 최적화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e511f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546e87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add417c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5e8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff32d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
